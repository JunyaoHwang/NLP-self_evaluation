# OGM-GE

## 论文背景

1. 以往的研究人员认为，不同模态的收敛速度往往不同，导致收敛不协调问题。

(不同模态的特征复杂度不同，数据量和数据质量不同等都会导致)

以往的解决方法:借助额外的单模态分类器或预训练模型来辅助多模态模型的训练 --> 花费额外的精力来训练额外的神经模块

2.多模态潜力未被完全挖掘。可能是有些多模态场景中表现较好的主导模型抑制其他模型优化。--> 优化不平衡现象

不平衡现象：梯度大小主要取决于当前模态在loss中的贡献。强模态训练得好，压低了∂L/∂f(x)，进而导致优化器更新步幅小，导致弱模态长期得不到优化

## 解决方案

动态梯度调制机制OGM-->缓解不平衡学习

引入额外高斯噪声GE-->实现泛化增强



### OGM

定义差异比率 $\rho$

其定义式为该batch内的每个样本，在音频和视频两个模态对应的模型上对于正确类上的softmax输出的和的比值。即：
$$
\rho_t^v = \frac{\sum_{i\in B_t}s_i^v}{\sum_{i\in B_t}s_i^a}
$$
其中$s_i^a,s_i^v$分别为第i个样本在正确类上的音频和视频的softmax输出概率。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20250923140746614.png" alt="image-20250923140746614" style="zoom:33%;" />

根据计算出的$\rho$实现梯度平衡：
$$
k_u^t = 
\begin{cases}
1 - \tanh(\alpha \cdot \rho_u^t) & \text{if } \rho_u^t > 1 \\
1 & \text{otherwise}
\end{cases}
$$


$\alpha$为超参数。这样就实现了对于在更新中占据主导的模态，使用$\rho$计算出缩放因子$k_t^u$,再使用1-tanh的计算降低主导模态在梯度更新中的权重，进而缓解不平衡学习。



但是削减梯度的同时带来了另外的问题：梯度变得更小的同时会导致梯度噪声会一并减弱，导致泛化能力下降。(引用文献提及)

因此OGM实现平衡的同时损害了模型的泛化性。

因此作者提出引入额外的高斯噪声弥补甚至增强噪声来恢复泛化能力

原始随机梯度计算式如下：
$$
\tilde{g}(θ_t^u)=∇_{\theta^u}L(θ_t^u)+ξ_t,ξ_t∼N(0,Σ_{sgd}(θ_t^u))
$$
现在引入$k_t^u$
$$
\theta_{t+1}^u = \theta_t^u-\eta*k_t^u*\tilde g(θ_t^u)
$$
展开g，得
$$
\tilde{g}(θ_t^u)=k_t^u∇_{\theta^u}L(θ_t^u)+k_t^uξ_t,k_t^uξ_t∼N(0,(k_t^u)^2Σ_{sgd}(θ_t^u))
$$
k显然小于1，所以这样显然减小了噪声的协方差。

为了弥补，于是引入了新的高斯噪声:
$$
h(θ_t^u)∼N(0,Σ_{sgd}(θ_t^u))
$$

$$
θ_{t+1}^u=θ_t^u−η⋅[k_t^u⋅\tilde g(θ_t^u)+h(θ_t^u)]
$$

$$
θ_{t+1}^u=θ_t^u−η⋅k_t^u⋅∇_{θ^u}L(θ_t^u)+η⋅ξ_t^{′′}
$$

其中：
$$
ξ_{t}^{''}∼N(0,((k_t^u)^2+1)⋅Σ_{sgd}(θ_t^u))
$$
实现了噪声增强。

## 算法流程

初始化

从训练集中抽取batch大小个样本

前馈输入到模型中

计算$\rho^u$

计算$k_t^u$

计算反向传播梯度g

根据g的协方差采样高斯分布的噪声h

将h作为噪声添加到梯度更新中，与g一同更新梯度

## 分析

优点：

1. 平衡梯度学习，允许弱模态得到有效更新
2. 增强了高斯随机噪声，提升了模型的泛化能力
3. 