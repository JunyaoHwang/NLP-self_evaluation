样本选择 --> 启发式的阈值 --> 降低模型的适应性
类别平衡问题
此背景下提出的SED
	1.样本选择
	2.使用均值教师模型进行标签校正
	3.样本重加权机制
	4.一致性正则化(对于干净样本)

过往的标签校正的方法
	噪声转移矩阵：难以估计
	模型预测：识别简单类的能力优于困难类，导致类别不平衡

样本选择与重加权
	1.干净子集和噪声子集的划分
		以往的方法需要先验的阈值，启发式导致偏差
	2.重加权
		置信度高-->大权重
		置信度低-->低权重
		缺点：现有的方法大都是启发式的


SED概述
	自适应概述:“自适应”指的是阈值、权重等训练关键量不靠预先设定的固定值或手工日程，而是由数据与模型当前状态在线（随训练、随类别）估计并动态更新，保留了少量通用且稳定的超参，并且对数据集不敏感
**论文主要的超参：EMA动量m，mean-teacher 模型alpha lambda_m（重加权）上限 初始化常量1/C
	自适应和类别平衡：为每个类别设置全局和局部阈值，动态更新
	阈值划分干净和噪声样本
	使用截断的正态分布对不同置信度的样本分配权重-->缓解不平衡标签校正引起的确认偏差
	加入额外正则化

算法流程：
	根据动态更新的阈值划分干净和噪声样本
	采用均值教师模型对噪声样本的标签进行纠正
	自适应地给噪声样本分配不同的权重
	梯度更新
	正则化项中添加了干净样本的一致性损失

算法实现
	1.本文使用交叉熵损失
	2.SCS-->样本选择，阈值
	
		
SCS 我们这里使用的是原标签 为何？
	因为我们是要去解决原标签是否可靠的问题，所以应该直接使用原标签
	伪标签更倾向于简单类，如果使用伪标签来更新阈值会导致干净子集会被简单类占据

全局阈值指数加权的更新后一项的含义：对各自原标签的信任度，开始时较低，训练到后面变高
//符合我们的要求：模型初始情况下表现差，需要更多的样本来训练。训练到后面模型能够较为准确地识别样本了，这种情况下我们应该提高阈值使得只让更可靠的样本输入模型。防止错误的样本干扰模型

易类与难类的界定

E(c) 含义：模型在全数据上对类别c的总体置信度 
易类--> 相近的类在该类的预测概率较大，所以E(c)较高
难类--> E(c)偏低，因为本类样本更模糊，容易被混淆，它的样本概率会被分给邻近类
这种情况下易类的E(c)会偏高，难类E(c)会偏低
易类偏高，训练的比较好，我们需要更高质量的样本对其进行训练，防止噪声干扰
难类偏低，我们更注重更多的样本进行训练，而不是质量(因为对于难类而言区分什么是难类的干净样本对模型而言本身也很困难)

T_c计算

在局部上，我们实现了易类阈值高，难类阈值低
在全局上，我们实现了训练初期阈值低，训练后期阈值高
总体而言，我们实现了
对于训练较好的类别，相比于大量的样本，其更注重质量，防止噪声使得泛化能力降低
对于训练较差的类别，相比于质量，我们更注重足够的样本使其训练

归一化Max{Ec}的原因：
1.防止阈值超过全局阈值，筛选过严而几乎得不到训练(使用其他归一化也可能出现这个问题)
2.对于标量缩放不敏感，如果所有E_c同比例缩放，比例不变




自适应平衡与重加权

SCR方法






