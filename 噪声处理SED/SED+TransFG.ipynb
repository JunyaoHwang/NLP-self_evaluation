{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3234195c",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "# 实验环境设置与项目导入\n",
    "\n",
    "**目标**: 克隆 `SED` 仓库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94b2caf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T04:58:05.375956Z",
     "iopub.status.busy": "2025-07-28T04:58:05.375735Z",
     "iopub.status.idle": "2025-07-28T04:58:06.217263Z",
     "shell.execute_reply": "2025-07-28T04:58:06.216373Z",
     "shell.execute_reply.started": "2025-07-28T04:58:05.375936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "克隆仓库 'https://github.com/shengmengmeng/SED.git'...\n",
      "Cloning into 'SED'...\n",
      "remote: Enumerating objects: 44, done.\u001b[K\n",
      "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
      "remote: Total 44 (delta 7), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (44/44), 1.09 MiB | 8.06 MiB/s, done.\n",
      "Resolving deltas: 100% (7/7), done.\n",
      "'SED' 已成功添加到系统路径。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "repo_dir = 'SED'  # 本地文件夹名\n",
    "repo_url = 'https://github.com/shengmengmeng/SED.git'\n",
    "\n",
    "\n",
    "if not os.path.exists(repo_dir):\n",
    "    print(f\"克隆仓库 '{repo_url}'...\")\n",
    "\n",
    "    !git clone {repo_url}\n",
    "else:\n",
    "\n",
    "    print(f\"仓库 '{repo_dir}' 已存在。\")\n",
    "\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.append(repo_dir)\n",
    "    print(f\"'{repo_dir}' 已成功添加到系统路径。\")\n",
    "else:\n",
    "    print(f\"'{repo_dir}' 已经在系统路径中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f55e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T04:58:06.219874Z",
     "iopub.status.busy": "2025-07-28T04:58:06.219642Z",
     "iopub.status.idle": "2025-07-28T04:58:18.167593Z",
     "shell.execute_reply": "2025-07-28T04:58:18.166864Z",
     "shell.execute_reply.started": "2025-07-28T04:58:06.219850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "设备:cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "class Config:\n",
    "    # 数据集参数\n",
    "    DATA_PATH = \"/kaggle/input/webfg400-train/train\"  # 修正变量名\n",
    "    TEST_DATA_PATH = \"/kaggle/input/webfg400-test-a/test_A\"\n",
    "    NUM_CLASSES = 12  # 我们只使用前12个类\n",
    "    IMAGE_SIZE = 224  # 细粒度识别通常需要更高分辨率\n",
    "    VALIDATION_RATIO = 0.1  # 从训练集中取10%作为验证集\n",
    "\n",
    "    # 模型参数\n",
    "    MODEL_NAME = 'vit_base_patch16_224' # TransFG 的基础模型\n",
    "    PRETRAINED = True\n",
    "    PART_SELECT_LAYER = 8 # 在第8层后选择关键区域\n",
    "    NUM_SELECTED_PARTS = 16 # 选择16个关键图像块\n",
    "\n",
    "    # 训练参数\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 8 # 可调\n",
    "    LR = 1e-5 #学习率\n",
    "    WEIGHT_DECAY = 1e-4 #权重衰减\n",
    "    SEED = 42\n",
    "\n",
    "    WARMUP_EPOCHS = 10 #用10轮初步学习\n",
    "    \n",
    "\n",
    "    OUTPUT_DIR = \"/kaggle/working/output\"\n",
    "\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "#输出目录\n",
    "os.makedirs(CFG.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "#随机种子\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(CFG.SEED)\n",
    "\n",
    "print(f\"设备:{CFG.DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b240b4",
   "metadata": {},
   "source": [
    "# CUB-200-2011 数据集定义\n",
    "\n",
    "**目标**: 创建一个自定义的 `Dataset` 类，用于加载 CUB 数据集。\n",
    "\n",
    "**说明**:\n",
    "- 这个类将只加载指定的12个类别 (文件夹 '001' 到 '012')。\n",
    "- 它会自动划分训练集和测试集 (80/20比例)。\n",
    "- 它会应用适当的数据增强和预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d917f30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T04:58:18.168834Z",
     "iopub.status.busy": "2025-07-28T04:58:18.168424Z",
     "iopub.status.idle": "2025-07-28T04:58:18.721897Z",
     "shell.execute_reply": "2025-07-28T04:58:18.721139Z",
     "shell.execute_reply.started": "2025-07-28T04:58:18.168812Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集创建完成:\n",
      " - 训练集样本数: 1001\n",
      " - 测试集样本数: 256\n"
     ]
    }
   ],
   "source": [
    "class FineGrainedCUBDataset(Dataset):\n",
    "    def __init__(self, root_dir, num_classes, train=True, transform=None, validation_ratio=0.1):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # 获取所有类别文件夹\n",
    "        class_folders = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        selected_folders = class_folders[:num_classes]\n",
    "\n",
    "        for label, class_folder in enumerate(selected_folders):\n",
    "            class_path = os.path.join(root_dir, class_folder)\n",
    "            images_in_class = sorted([os.path.join(class_path, f) for f in os.listdir(class_path) \n",
    "                                    if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            \n",
    "            # 划分训练集和验证集\n",
    "            split_idx = int(len(images_in_class) * (1 - validation_ratio))\n",
    "            if self.train:\n",
    "                self.image_paths.extend(images_in_class[:split_idx])\n",
    "                self.labels.extend([label] * split_idx)\n",
    "            else:\n",
    "                self.image_paths.extend(images_in_class[split_idx:])\n",
    "                self.labels.extend([label] * (len(images_in_class) - split_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label, idx\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted([os.path.join(test_dir, f) for f in os.listdir(test_dir) \n",
    "                                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # 返回图像和文件名，用于生成提交结果\n",
    "        filename = os.path.basename(img_path)\n",
    "        return image, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce96478",
   "metadata": {},
   "source": [
    "# TransFG 模型定义\n",
    "\n",
    "实现 TransFG 模型的关键部分。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe29ed7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T04:58:18.723010Z",
     "iopub.status.busy": "2025-07-28T04:58:18.722743Z",
     "iopub.status.idle": "2025-07-28T04:58:18.743952Z",
     "shell.execute_reply": "2025-07-28T04:58:18.743234Z",
     "shell.execute_reply.started": "2025-07-28T04:58:18.722988Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransFG 模型定义完成。\n"
     ]
    }
   ],
   "source": [
    "class PartSelection(nn.Module):\n",
    "    #根据注意力矩阵选择最重要的图像块\n",
    "    \n",
    "    def __init__(self, num_selected_parts):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.num_selected_parts = num_selected_parts #选取图块数量\n",
    "\n",
    "    def forward(self, x, attention_matrix):\n",
    "        \"\"\"\n",
    "        根据注意力权重选择最重要的图像块\n",
    "        参数:\n",
    "            x: 特征张量 [batch_size, num_patches+1, embed_dim]\n",
    "            attention_matrix: 注意力权重矩阵 [batch_size, num_heads, num_patches+1, num_patches+1]\n",
    "        返回:\n",
    "            selected_parts: 选中的图像块特征 [batch_size, num_selected_parts, embed_dim]\n",
    "        \"\"\"\n",
    "        # 提取CLS token对所有图像块的注意力，并在头维度上平均\n",
    "        cls_attention = attention_matrix[:, :, 0, 1:].mean(dim=1)  \n",
    "        \n",
    "        # 选择注意力最高的K个图像块的索引\n",
    "        _, top_indices = torch.topk(cls_attention, self.num_selected_parts, dim=1) \n",
    "        \n",
    "        top_indices = top_indices + 1\n",
    "        \n",
    "        batch_indices = torch.arange(x.size(0)).unsqueeze(1).to(x.device) #批次索引\n",
    "        \n",
    "        # 提取选定的图像块特征\n",
    "        selected_parts = x[batch_indices, top_indices] \n",
    "        return selected_parts\n",
    "\n",
    "class TransFG(nn.Module):\n",
    "    \"\"\"\n",
    "    TransFG模型:基于Vision Transformer的细粒度分类模型\n",
    "    结合全局特征和关键区域特征进行细粒度识别\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, num_classes, pretrained=True, part_select_layer=8, num_selected_parts=16):\n",
    "        \"\"\"\n",
    "            model_name: 基础ViT模型名称\n",
    "            num_classes: 分类类别数\n",
    "            pretrained: 是否使用预训练权重\n",
    "            part_select_layer: 在哪一层之后选择关键区域\n",
    "            num_selected_parts: 选择的关键图像块数量\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.part_select_layer = part_select_layer\n",
    "        \n",
    "        self.vit = timm.create_model(model_name, pretrained=pretrained)\n",
    "        \n",
    "        # 将ViT模型分为两部分，以便在中间提取关键区域\n",
    "        self.vit_part1 = nn.Sequential(*self.vit.blocks[:part_select_layer])  # 前半部分Transformer块\n",
    "        self.vit_part2 = nn.Sequential(*self.vit.blocks[part_select_layer:])  # 后半部分Transformer块\n",
    "        \n",
    "        # 关键区域选择器\n",
    "        self.part_selector = PartSelection(num_selected_parts)\n",
    "        \n",
    "        # 获取嵌入维度\n",
    "        embed_dim = self.vit.embed_dim\n",
    "        \n",
    "        # 分类头\n",
    "        self.head = nn.Linear(embed_dim * 2, num_classes)\n",
    "        \n",
    "        # 移除原始ViT的分类头\n",
    "        self.vit.head = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        参数:\n",
    "            x: 输入图像 [batch_size, channels, height, width]\n",
    "        返回:\n",
    "            logits: 分类logits [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # 图像切片嵌入\n",
    "        x = self.vit.patch_embed(x) \n",
    "        \n",
    "        # 分类token\n",
    "        cls_token = self.vit.cls_token.expand(x.shape[0], -1, -1) \n",
    "        x = torch.cat((cls_token, x), dim=1)          \n",
    "        # 位置编码\n",
    "        x = x + self.vit.pos_embed\n",
    "        x = self.vit.pos_drop(x)\n",
    "\n",
    "        for blk in self.vit_part1:\n",
    "            x = blk(x)\n",
    "        \n",
    "        attn_weights = self.vit_part1[-1].attn.get_attention_map()\n",
    "        selected_parts = self.part_selector(x, attn_weights)\n",
    "        \n",
    "        part_cls_token = self.vit.cls_token.expand(selected_parts.shape[0], -1, -1)\n",
    "        part_x = torch.cat([part_cls_token, selected_parts], dim=1)\n",
    "        \n",
    "        global_stream = self.vit_part2(x)\n",
    "        global_cls = global_stream[:, 0]\n",
    "\n",
    "        part_stream = self.vit_part2(part_x)\n",
    "        part_cls = part_stream[:, 0]\n",
    "        \n",
    "        final_feature = torch.cat([global_cls, part_cls], dim=1)\n",
    "        logits = self.head(final_feature)\n",
    "        return logits\n",
    "\n",
    "# 在 timm 的 ViTBlock 中添加一个方法来获取注意力图\n",
    "def get_attention_map(self):\n",
    "    return self.attention_map #返回注意力权重矩阵\n",
    "\n",
    "timm.models.vision_transformer.Attention.get_attention_map = get_attention_map\n",
    "\n",
    "\n",
    "#自注意力机制\n",
    "def forward_attn(self, x):\n",
    "    B, N, C = x.shape\n",
    "    qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "    q, k, v = qkv.unbind(0)\n",
    "    attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "    attn = attn.softmax(dim=-1)\n",
    "    self.attention_map = attn \n",
    "    attn = self.attn_drop(attn)\n",
    "    x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "    x = self.proj(x)\n",
    "    x = self.proj_drop(x)\n",
    "    return x\n",
    "\n",
    "timm.models.vision_transformer.Attention.forward = forward_attn\n",
    "\n",
    "print(\"TransFG 模型定义完成。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d823fe",
   "metadata": {},
   "source": [
    "# SED 训练与评估函数\n",
    "\n",
    "SED 训练策略的核心逻辑和标准的评估函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c0f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T04:58:18.745033Z",
     "iopub.status.busy": "2025-07-28T04:58:18.744778Z",
     "iopub.status.idle": "2025-07-28T04:58:18.760587Z",
     "shell.execute_reply": "2025-07-28T04:58:18.759857Z",
     "shell.execute_reply.started": "2025-07-28T04:58:18.745010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SED 训练和评估函数定义完成。\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    #评估模型在验证集上的准确率\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 获取预测类别\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# 添加函数用于生成测试集的预测结果\n",
    "def predict_test_set(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    filenames = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, image_filenames in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            predictions.extend(predicted.cpu().numpy().tolist())\n",
    "            filenames.extend(image_filenames)\n",
    "    \n",
    "    return filenames, predictions\n",
    "\n",
    "def train_sed_epoch(epoch, model, train_loader, optimizer, device, num_classes):\n",
    "    #使用SED策略训练一个epoch，将样本分为易学习和难学习两类分别处理\n",
    "    model.train()\n",
    "    \n",
    "    # 计算每个样本的损失值\n",
    "    losses = torch.zeros(len(train_loader.dataset))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels, indices in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels, reduction='none')  # 计算单个样本损失\n",
    "            for i, idx in enumerate(indices):\n",
    "                losses[idx] = loss[i].item()\n",
    "    model.train()\n",
    "\n",
    "    # 使用GMM将样本划分为干净样本和困难样本 高斯混合模型，多个正态分布混合\n",
    "    clean_idx, noisy_idx = [], []\n",
    "    for c in range(num_classes):\n",
    "        # 提取每个类别的样本索引\n",
    "        class_indices = np.where(np.array(train_loader.dataset.labels) == c)[0]\n",
    "        if len(class_indices) == 0: continue\n",
    "        \n",
    "        # 使用二分量GMM对损失进行聚类 GMM可以实现自适应阈值\n",
    "        class_losses = losses[class_indices].numpy().reshape(-1, 1)\n",
    "        gmm = GaussianMixture(n_components=2, max_iter=10, tol=1e-2, reg_covar=5e-4)\n",
    "        gmm.fit(class_losses)\n",
    "        clean_component_idx = gmm.means_.argmin()  # 损失较小的分量为干净样本\n",
    "        pred = gmm.predict(class_losses)\n",
    "        clean_mask = (pred == clean_component_idx)\n",
    "        \n",
    "        # 划分干净样本和困难样本\n",
    "        clean_idx.extend(class_indices[clean_mask])\n",
    "        noisy_idx.extend(class_indices[~clean_mask])\n",
    "\n",
    "    # 使用标准交叉熵损失训练干净样本\n",
    "    clean_sampler = torch.utils.data.SubsetRandomSampler(clean_idx)\n",
    "    clean_loader = DataLoader(train_loader.dataset, batch_size=CFG.BATCH_SIZE, sampler=clean_sampler, num_workers=2)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{CFG.EPOCHS}] - 划分完成. 干净样本: {len(clean_idx)}, 困难样本: {len(noisy_idx)}\")\n",
    "\n",
    "    for images, labels, _ in clean_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 对困难样本使用伪标签和类别平衡策略训练\n",
    "    if len(noisy_idx) > 0:\n",
    "        noisy_sampler = torch.utils.data.SubsetRandomSampler(noisy_idx)\n",
    "        noisy_loader = DataLoader(train_loader.dataset, batch_size=CFG.BATCH_SIZE, sampler=noisy_sampler, num_workers=2)\n",
    "        \n",
    "        # 生成伪标签\n",
    "        model.eval()\n",
    "        pseudo_labels = torch.zeros(len(train_loader.dataset), num_classes).to(device)\n",
    "        with torch.no_grad():\n",
    "            for images, _, indices in noisy_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                pseudo_labels[indices] = F.softmax(outputs, dim=1)  # 软标签\n",
    "        model.train()\n",
    "        \n",
    "        # 使用伪标签和类别平衡权重训练\n",
    "        for images, labels, indices in noisy_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            pt = pseudo_labels[indices]\n",
    "            \n",
    "            # 计算类别平衡权重\n",
    "            pt_per_class = pt.sum(dim=0)\n",
    "            pt_per_class = pt_per_class / pt_per_class.sum()\n",
    "            class_weights = (1.0 / (num_classes * pt_per_class)).to(device)\n",
    "            batch_weights = torch.matmul(pt, class_weights)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            # 使用KL散度损失\n",
    "            loss = -torch.sum(F.log_softmax(outputs, dim=1) * pt, dim=1)\n",
    "            loss = (loss * batch_weights).mean()  # 应用权重\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "print(\"SED 训练和评估函数定义完成。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b5a50",
   "metadata": {},
   "source": [
    "# 主程序：模型训练与评估\n",
    "\n",
    "**目标**: 将所有部分组合在一起，启动完整的训练和评估流程。\n",
    "\n",
    "**说明**:\n",
    "1.  实例化模型、优化器和数据加载器。\n",
    "2.  执行 `WARMUP_EPOCHS` 次数的标准训练。\n",
    "3.  执行剩余次数的 `SED` 训练。\n",
    "4.  在每个 epoch 结束后，在测试集上评估模型性能，并保存表现最好的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343efc8-5dc7-4308-82f9-f32cb0ce0b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T04:58:18.761460Z",
     "iopub.status.busy": "2025-07-28T04:58:18.761294Z",
     "iopub.status.idle": "2025-07-28T04:58:22.272680Z",
     "shell.execute_reply": "2025-07-28T04:58:22.271938Z",
     "shell.execute_reply.started": "2025-07-28T04:58:18.761446Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集创建完成:\n",
      " - 训练集样本数: 1001\n",
      " - 测试集样本数: 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b26a2a85b04aa08dfb160c243a8482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集创建完成:\n",
      " - 训练集样本数: 1001\n",
      " - 测试集样本数: 256\n"
     ]
    }
   ],
   "source": [
    "# --- 定义数据预处理和增强 ---\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG.IMAGE_SIZE, CFG.IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG.IMAGE_SIZE, CFG.IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# --- 1. 实例化模型、优化器和数据加载器 ---\n",
    "model = TransFG(\n",
    "    model_name=CFG.MODEL_NAME,\n",
    "    num_classes=CFG.NUM_CLASSES,\n",
    "    pretrained=CFG.PRETRAINED,\n",
    "    part_select_layer=CFG.PART_SELECT_LAYER,\n",
    "    num_selected_parts=CFG.NUM_SELECTED_PARTS\n",
    ").to(CFG.DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CFG.LR, weight_decay=CFG.WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.EPOCHS)\n",
    "\n",
    "# --- 创建数据集实例 ---\n",
    "try:\n",
    "    train_dataset = FineGrainedCUBDataset(\n",
    "        CFG.DATA_PATH, \n",
    "        CFG.NUM_CLASSES, \n",
    "        train=True, \n",
    "        transform=train_transform, \n",
    "        validation_ratio=CFG.VALIDATION_RATIO\n",
    "    )\n",
    "    \n",
    "    val_dataset = FineGrainedCUBDataset(\n",
    "        CFG.DATA_PATH, \n",
    "        CFG.NUM_CLASSES, \n",
    "        train=False, \n",
    "        transform=val_transform, \n",
    "        validation_ratio=CFG.VALIDATION_RATIO\n",
    "    )\n",
    "    \n",
    "    test_dataset = TestDataset(CFG.TEST_DATA_PATH, transform=val_transform)\n",
    "    \n",
    "    print(f\"数据集创建完成:\")\n",
    "    print(f\" - 训练集样本数: {len(train_dataset)}\")\n",
    "    print(f\" - 验证集样本数: {len(val_dataset)}\")\n",
    "    print(f\" - 测试集样本数: {len(test_dataset)}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"错误: {e}\")\n",
    "    print(\"确保已添加正确的数据集路径。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2d989-a12b-47dd-91c9-d88b31519191",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ffeac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T04:59:38.942433Z",
     "iopub.status.busy": "2025-07-28T04:59:38.941752Z",
     "iopub.status.idle": "2025-07-28T05:50:02.402694Z",
     "shell.execute_reply": "2025-07-28T05:50:02.401715Z",
     "shell.execute_reply.started": "2025-07-28T04:59:38.942398Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1/50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f399e2b807f4b4991f9c0f8b1a0d929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "热身中:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - 测试集准确率: 75.00%\n",
      "--- Epoch 2/50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf26cd54ad542cc82287c8e3441016a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "热身中:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] - 测试集准确率: 75.39%\n",
      "--- Epoch 3/50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66648aa3d8504a45b2df1acf9d746f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "热身中:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] - 测试集准确率: 80.08%\n",
      "--- Epoch 4/50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd3e3c241204018aaff64ae24c3b99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "热身中:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] - 测试集准确率: 81.25%\n",
      "--- Epoch 5/50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e39c4252d01488cbdfb86ce274401ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "热身中:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] - 测试集准确率: 82.03%\n",
      "--- Epoch 6/50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b72754249142e8965c39065f8c30f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "热身中:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] - 测试集准确率: 81.64%\n",
      "--- Epoch 7/50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd02accef98c4280a0c604493fe34c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "热身中:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] - 测试集准确率: 82.81%\n",
      "--- Epoch 8/50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c39bee767b48ccba4ef79a846edc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "热身中:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] - 测试集准确率: 83.20%\n",
      "--- Epoch 9/50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ab384155ab49d6b70172e49e2bfb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "热身中:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] - 测试集准确率: 81.25%\n",
      "--- Epoch 10/50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de7c3be646f43c4a6822f6070646fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "热身中:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] - 测试集准确率: 83.20%\n",
      "--- Epoch 11/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [11/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [11/50] - 测试集准确率: 84.38%\n",
      "--- Epoch 12/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [12/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [12/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 13/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [13/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [13/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 14/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [14/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [14/50] - 测试集准确率: 84.38%\n",
      "--- Epoch 15/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [15/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [15/50] - 测试集准确率: 84.38%\n",
      "--- Epoch 16/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [16/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [16/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 17/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [17/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [17/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 18/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [18/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [18/50] - 测试集准确率: 84.38%\n",
      "--- Epoch 19/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [19/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [19/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 20/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [20/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [20/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 21/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [21/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [21/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 22/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [22/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [22/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 23/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [23/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [23/50] - 测试集准确率: 84.38%\n",
      "--- Epoch 24/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [24/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [24/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 25/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [25/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [25/50] - 测试集准确率: 84.38%\n",
      "--- Epoch 26/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [26/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [26/50] - 测试集准确率: 84.38%\n",
      "--- Epoch 27/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [27/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [27/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 28/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [28/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [28/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 29/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [29/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [29/50] - 测试集准确率: 84.38%\n",
      "--- Epoch 30/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [30/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [30/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 31/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [31/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [31/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 32/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [32/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [32/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 33/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [33/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [33/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 34/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [34/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [34/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 35/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [35/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [35/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 36/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [36/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [36/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 37/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [37/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [37/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 38/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [38/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [38/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 39/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [39/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [39/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 40/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [40/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [40/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 41/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [41/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [41/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 42/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [42/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [42/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 43/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [43/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [43/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 44/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [44/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [44/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 45/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [45/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [45/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 46/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [46/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [46/50] - 测试集准确率: 83.59%\n",
      "--- Epoch 47/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [47/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [47/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 48/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [48/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [48/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 49/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [49/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [49/50] - 测试集准确率: 83.98%\n",
      "--- Epoch 50/50 ---\n",
      "模式: SED 训练\n",
      "Epoch [50/50] - 划分完成. 干净样本: 994, 困难样本: 7\n",
      "Epoch [50/50] - 测试集准确率: 83.98%\n",
      "\n",
      "--- 训练完成 ---\n",
      "最佳测试集准确率: 84.38%\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# --- 2. 开始训练 ---\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(CFG.EPOCHS):\n",
    "    print(f\"--- Epoch {epoch+1}/{CFG.EPOCHS} ---\")\n",
    "    \n",
    "    if epoch < CFG.WARMUP_EPOCHS:\n",
    "        print(\"模式: 标准训练 (热身)\")\n",
    "        model.train()\n",
    "        for images, labels, _ in tqdm(train_loader, desc=\"训练中\"):\n",
    "            images, labels = images.to(CFG.DEVICE), labels.to(CFG.DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    else:\n",
    "        # --- SED 训练 ---\n",
    "        print(\"模式: SED 训练\")\n",
    "        train_sed_epoch(epoch, model, train_loader, optimizer, CFG.DEVICE, CFG.NUM_CLASSES)\n",
    "\n",
    "    # --- 评估与保存 ---\n",
    "    current_accuracy = evaluate(model, val_loader, CFG.DEVICE)\n",
    "    print(f\"Epoch [{epoch+1}/{CFG.EPOCHS}] - 验证集准确率: {current_accuracy:.2f}%\")\n",
    "\n",
    "    \n",
    "    if current_accuracy > best_accuracy:\n",
    "        best_accuracy = current_accuracy\n",
    "        \n",
    "        model_path = os.path.join(CFG.OUTPUT_DIR, 'best_model.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"得分更高，模型已保存至: {model_path}\")\n",
    "            \n",
    "    scheduler.step()\n",
    "\n",
    "print(\"\\n--- 训练完成 ---\")\n",
    "print(f\"最佳验证集准确率: {best_accuracy:.2f}%\")\n",
    "\n",
    "# 对测试集进行预测并保存结果\n",
    "print(\"\\n--- 生成测试集预测结果 ---\")\n",
    "model.load_state_dict(torch.load(os.path.join(CFG.OUTPUT_DIR, 'best_model.pth')))\n",
    "filenames, predictions = predict_test_set(model, test_loader, CFG.DEVICE)\n",
    "\n",
    "# 创建提交文件\n",
    "import pandas as pd\n",
    "submission = pd.DataFrame({\n",
    "    'image': filenames,\n",
    "    'label': predictions\n",
    "})\n",
    "submission.to_csv(os.path.join(CFG.OUTPUT_DIR, 'submission.csv'), index=False)\n",
    "print(f\"测试集预测结果已保存至: {os.path.join(CFG.OUTPUT_DIR, 'submission.csv')}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7948460,
     "sourceId": 12585020,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7947081,
     "sourceId": 12582994,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 85977438,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
