# I<sup>2</sup>MOE 论文

## <span style='color:red'>问题背景</span>

### 模态融合：传统的模态融合方法存在局限性：



* 无法考虑模态之间的异构交互
* 在揭示数据中固有的多模态交互时缺乏可解释性

#### 详细理解这两点:



##### **1.模态之间的异构交互：**

不同模态在语义结构、统计分布、信息密度和表达形式上存在差异时，如何进行有效的信息融合和对齐

###### 如何理解异构？

不同模态的表达方式完全不一样，文字是字串，图像是一张张像素点，声音是波形。各自的表达方式不同无法直接对齐。

对齐：对齐有多种形式。

* 模态级对齐：整个文本和整个图像对齐
* 片段级对齐：文本片段<->图像区域(沙发<-->猫)
* 时间级对齐：在视频或者语音中 某个时刻的语音<-->某一帧画面

回归异构交互的定义：

综上而言，不同模态的信息的表达方式不一样，导致它们之间的交互和整合不是直接对应的，而需要特殊的机制来弥合差异





#####  在揭示数据中固有的多模态交互时缺乏可解释性

###### 数据中固有的多模态交互

在多模态的研究中我们希望机器能够自动发现模态之间的交互规律。比如让文本的"猫"字对应图像中的猫，让鼓掌的动作对应"啪啪"的声响。

###### 缺乏可解释性

使用深度神经网络学习交互时，尽管可以看到模型的输入输出，但是我们很难解释清楚模型内部"为什么把某个图像区域和某个词语对应起来"。



### PID框架

模态的信息分为三类：

每个模态所特有的信息，其他模态不具备 (独特性)

两个或者多个模态所共有的信息 (冗余性)

靠多个模态组合产生的新信息(协同性)



理论很不错，但是实际应用少：

"在多模态融合框架中直接利用 PID 来提高任务性能和模型可解释性的机会在很大程度上仍未得到探索"



## <span style='color:red'> I<sup>2</sup>MOE</span>

混合专家模型：由多个融合模型组成的一个大的交互交互模型

#### 重加权

根据编码结果为每个专家生成权重



#### 对于两个交互模态：



设计四个交互专家：其中两个分别捕捉模态1和模态2的独特信息

另外一个的捕捉冗余信息，剩下一个捕捉协同信息

把四个专家分别记为Funi1, Funi2, Fsyn, Fred.

最后的分类结果由四个训练好的专家加权得出。



专家的训练：

首先，为了得到仅依靠模态1的输出y1，我们保留模态1的嵌入，将模态2的嵌入换为随机向量。同理可得到仅依靠模态2的输出y2.

正常预测的结果为y12。

对于专家Funi1，其只捕捉模态1的信息，不捕捉模态2的信息。

于是，我们把仅依靠模态1的输出y1作为正例，仅依靠模态2的输出作为负例，计算Loss_Funi1(y12,y1,y2)。



作者在代码实现中采用了Triplet损失：
$$
L_{triplet}=max(0,d(y_1,y_{12})−d(y_2,y_{12})+margin)
$$

$$
d(x,y) = || x - y||_2
$$



<span style='color:red'>为何作者要使用triplet损失？他是怎么</span>







其中p,margin为超参数。

margin含义:表示y12到y1的距离至少比y12到y2的距离近margin这么多。否则要给予大于0的部分这么多惩罚。

换句话说，我们希望y12到正例的距离比y12到负例的距离小margin这么多。

margin直接决定了专家的"挑剔程度"



Funi2同理。



对于专家Fsyn，其捕捉仅靠模态1 或者模态2  无法得出的信息。即只能靠两个模态共同作用才能得出的信息。

协同专家的目标是学习那些仅当两个模态结合时才出现的信息，而这些信息在 y1 和 y2 中是缺失的。我们要找在y1和y2中没有的信息。那么我们应该把y1,y2缺失的信息作为正例，而把y1,y2都有的信息作为负例。

对此，我们把y1,y2均视为负例，让y12远离这两个样本。让其既不像y1,也不像y2。作者使用了余弦相似度版协同损失。
$$
L_{syn}^{(i)}=cos(y_{12},y_i)=\frac{y_{12}^⊤y_i}{∥y_{12}∥_2∥y_i∥_2},\quad i∈{\{1,2\}}
$$

$$
\mathcal{L}_{\text{syn}}= \frac{1}{2B}\sum_{b=1}^{B}\Bigl[\cos(\mathbf{y}_{12}^{(b)},\,\mathbf{y}_{1}^{(b)}) + \cos(\mathbf{y}_{12}^{(b)},\,\mathbf{y}_{2}^{(b)})\Bigr]
$$
模型会朝着cos为-1的方向，即y12和y1,y2尽可能相反的方向进行更新。

<div style='color:red'>为什么要使用这个函数？
    余弦对向量的长度不敏感，我们更多考量方向相似性。进而让模型更注重相对关系<br>
    数值更稳定，保持在1到-1之间<br>
    尝试：换成其他损失函数呢？<br>
    min 1-MSE(归一化)等？

</div>



对于专家Fred,和Fsyn很相似:
$$
\mathcal{L}_{\text{red}}= \frac{1}{2B}\sum_{b=1}^{B}\Bigl[1 - \cos(\mathbf{y}_{12}^{(b)},\,\mathbf{y}_{1}^{(b)}) + 1 - \cos(\mathbf{y}_{12}^{(b)},\,\mathbf{y}_{2}^{(b)})\Bigr]
$$
这样一来就使得cos值越小越罚，使得模型会朝着cos值为1的方向，即y12和y1,y2相同的方向进行更新。

至此，四个损失我们都得到了。

作者将这四个损失加到了总损失上：
$$
L_{total} = L_f +\frac{\lambda_{int}}{E} \sum^E_{i=1}L_{int}^i
$$




#### 多个模态的交互

注意到对于n个模态的交互，若采用两两交互的方式，会导致专家数量呈现指数式的增长，也不便于提取需要三个及以上模态共同推导得出的信息。为此，对于M个模态，作者设计了M+2个专家，其中M个用于提取各个模态的独特信息，剩余两个分别用于提取协同信息和冗余信息。







### 算法流程简述

数据x<sub>i</sub>-- encoding -- > 生成嵌入z<sub>i</sub>

根据z<sub>i</sub>自适应地生成W

初始化专家

训练：

​	加权得出预测结果

​	向前传播计算任务损失

​	进行额外的向前传播计算专家损失

​	Loss = 专家损失*系数+ 任务损失

​	更新参数(权重也会跟着更新)

训练结束



## 分析



算法优点：

将pid过程显式地添加到了模型中

各个专家各司其职，专家之间是分开的，可以单独输出分析。提供了不错的解释性

算法缺点：

1. 不同专家的损失函数直接相加，是否存在相互抵消的问题？即对于一个专家而言，其他专家产生的损失函数可能对该专家的更新具有抑制作用。

2. 同样的，高权重的专家会对低权重的专家造成更新抑制-->但由于融合训练的损失存在会缓解这种情况

3. 在某些数据集上可能出现专家意见分歧很大的情况，模型在专家意见冲突时的整合能力有限，需要更好的分歧处理机制。

4. 随机向量是否妥当？偶然性
5. 交互专家是人为预设的，缺乏自适应机制。因为某些任务中存在多种复杂的冗余或者协同模式，单个专家不一定能捕捉。(情况并不常见)
6. 重加权机制缺乏可解释性
7. triplet损失对margin敏感，文中没有讨论这方面的鲁棒性和不同margin对损失的影响
8. 训练成本问题



